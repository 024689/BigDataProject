[2024-01-29T09:09:45.532+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: manage_data_lake_dag.spark_job_formatted manual__2024-01-29T09:08:59.525451+00:00 [queued]>
[2024-01-29T09:09:45.539+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: manage_data_lake_dag.spark_job_formatted manual__2024-01-29T09:08:59.525451+00:00 [queued]>
[2024-01-29T09:09:45.539+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 6
[2024-01-29T09:09:45.626+0000] {taskinstance.py:2191} INFO - Executing <Task(SparkSubmitOperator): spark_job_formatted> on 2024-01-29 09:08:59.525451+00:00
[2024-01-29T09:09:45.630+0000] {standard_task_runner.py:60} INFO - Started process 76349 to run task
[2024-01-29T09:09:45.635+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'manage_data_lake_dag', 'spark_job_formatted', 'manual__2024-01-29T09:08:59.525451+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/data_lake_dag.py', '--cfg-path', '/tmp/tmpqoe1rw1j']
[2024-01-29T09:09:45.638+0000] {standard_task_runner.py:88} INFO - Job 65: Subtask spark_job_formatted
[2024-01-29T09:09:45.673+0000] {task_command.py:423} INFO - Running <TaskInstance: manage_data_lake_dag.spark_job_formatted manual__2024-01-29T09:08:59.525451+00:00 [running]> on host instance-1.europe-west9-a.c.data-lake-project-409321.internal
[2024-01-29T09:09:45.726+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='juniortemgoua0' AIRFLOW_CTX_DAG_ID='manage_data_lake_dag' AIRFLOW_CTX_TASK_ID='spark_job_formatted' AIRFLOW_CTX_EXECUTION_DATE='2024-01-29T09:08:59.525451+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-01-29T09:08:59.525451+00:00'
[2024-01-29T09:09:45.731+0000] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2024-01-29T09:09:45.732+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master yarn --name arrow-spark --class RawToFormatted --queue root.default /home/juniortemgoua0/DataLake/jobs/processes/scala/spark_process/target/scala-2.12/spark_job_2.12-0.1.0.jar gs://data-lake-buck
[2024-01-29T09:09:48.396+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO SparkContext: Running Spark version 3.5.0
[2024-01-29T09:09:48.401+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO SparkContext: OS info Linux, 5.15.0-1049-gcp, amd64
[2024-01-29T09:09:48.407+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO SparkContext: Java version 17.0.9
[2024-01-29T09:09:48.579+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-01-29T09:09:48.841+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceUtils: ==============================================================
[2024-01-29T09:09:48.841+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-01-29T09:09:48.842+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceUtils: ==============================================================
[2024-01-29T09:09:48.843+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO SparkContext: Submitted application: RawToFormatted
[2024-01-29T09:09:48.902+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-01-29T09:09:48.924+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2024-01-29T09:09:48.927+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-01-29T09:09:49.054+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SecurityManager: Changing view acls to: juniortemgoua0
[2024-01-29T09:09:49.056+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SecurityManager: Changing modify acls to: juniortemgoua0
[2024-01-29T09:09:49.057+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SecurityManager: Changing view acls groups to:
[2024-01-29T09:09:49.058+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SecurityManager: Changing modify acls groups to:
[2024-01-29T09:09:49.059+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: juniortemgoua0; groups with view permissions: EMPTY; users with modify permissions: juniortemgoua0; groups with modify permissions: EMPTY
[2024-01-29T09:09:49.453+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO Utils: Successfully started service 'sparkDriver' on port 46191.
[2024-01-29T09:09:49.497+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SparkEnv: Registering MapOutputTracker
[2024-01-29T09:09:49.539+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SparkEnv: Registering BlockManagerMaster
[2024-01-29T09:09:49.569+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-01-29T09:09:49.570+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-01-29T09:09:49.624+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-01-29T09:09:49.650+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e6171b0f-c798-4088-a25f-4281213dac1b
[2024-01-29T09:09:49.674+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-01-29T09:09:49.729+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-01-29T09:09:49.939+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:49 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-01-29T09:09:50.066+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-01-29T09:09:50.121+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:50 INFO SparkContext: Added JAR file:/home/juniortemgoua0/DataLake/jobs/processes/scala/spark_process/target/scala-2.12/spark_job_2.12-0.1.0.jar at spark://instance-1.europe-west9-a.c.data-lake-project-409321.internal:46191/jars/spark_job_2.12-0.1.0.jar with timestamp 1706519388377
[2024-01-29T09:09:50.426+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:50 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2024-01-29T09:09:51.645+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:52.646+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:53.647+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:54.648+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:55.649+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:56.650+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:57.651+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:58.652+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:09:59.653+0000] {spark_submit.py:571} INFO - 24/01/29 09:09:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:00.655+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:01.669+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:01 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:02.670+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:03.672+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:04.673+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:05.674+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:06.675+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:07.676+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:08.677+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:09.678+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:10.679+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:10.687+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:10 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 38595ms.
[2024-01-29T09:10:50.281+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:51.282+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:52.283+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:53.284+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:54.286+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:55.287+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:56.288+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:57.288+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:58.290+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:59.290+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:10:59.294+0000] {spark_submit.py:571} INFO - 24/01/29 09:10:59 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 2 failover attempts. Trying to failover after sleeping for 33160ms.
[2024-01-29T09:11:33.457+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:34.458+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:35.459+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:36.459+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:37.461+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:38.462+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:39.463+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:40.464+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:41.464+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:42.465+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:11:42.469+0000] {spark_submit.py:571} INFO - 24/01/29 09:11:42 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 3 failover attempts. Trying to failover after sleeping for 39276ms.
[2024-01-29T09:12:22.747+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:23.748+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:24.749+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:25.750+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:26.751+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:27.752+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:28.753+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:29.754+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:30.754+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:31.756+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:12:31.759+0000] {spark_submit.py:571} INFO - 24/01/29 09:12:31 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 4 failover attempts. Trying to failover after sleeping for 43120ms.
[2024-01-29T09:13:15.882+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:16.883+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:17.884+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:18.885+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:19.886+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:20.886+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:21.887+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:22.888+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:23.890+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:24.891+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:13:24.895+0000] {spark_submit.py:571} INFO - 24/01/29 09:13:24 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 5 failover attempts. Trying to failover after sleeping for 44968ms.
[2024-01-29T09:14:10.864+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:11.865+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:12.866+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:13.867+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:14.868+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:15.869+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:16.870+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:17.871+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:18.872+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:19.873+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:19.877+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:19 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 6 failover attempts. Trying to failover after sleeping for 31063ms.
[2024-01-29T09:14:51.942+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:52.943+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:53.944+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:54.945+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:55.946+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:56.947+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:57.948+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:58.949+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:14:59.950+0000] {spark_submit.py:571} INFO - 24/01/29 09:14:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:15:00.951+0000] {spark_submit.py:571} INFO - 24/01/29 09:15:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-29T09:15:00.954+0000] {spark_submit.py:571} INFO - 24/01/29 09:15:00 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 7 failover attempts. Trying to failover after sleeping for 18789ms.
[2024-01-29T09:15:04.153+0000] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 76349. PIDs of all processes in the group: [76350, 76349]
[2024-01-29T09:15:04.154+0000] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 76349
[2024-01-29T09:15:04.154+0000] {taskinstance.py:2450} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-01-29T09:15:04.155+0000] {spark_submit.py:697} INFO - Sending kill signal to spark-submit
[2024-01-29T09:15:04.181+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/juniortemgoua0/DataLake/venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/juniortemgoua0/DataLake/venv/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self._application)
  File "/home/juniortemgoua0/DataLake/venv/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 490, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
  File "/home/juniortemgoua0/DataLake/venv/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 539, in _process_spark_submit_log
    for line in itr:
  File "/home/juniortemgoua0/DataLake/venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2452, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-01-29T09:15:04.185+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=manage_data_lake_dag, task_id=spark_job_formatted, execution_date=20240129T090859, start_date=20240129T090945, end_date=20240129T091504
[2024-01-29T09:15:04.198+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 65 for task spark_job_formatted (Task received SIGTERM signal; 76349)
[2024-01-29T09:15:04.227+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=76349, status='terminated', exitcode=1, started='09:09:44') (76349) terminated with exit code 1
[2024-01-29T09:15:04.228+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=76350, status='terminated', started='09:09:44') (76350) terminated with exit code None
